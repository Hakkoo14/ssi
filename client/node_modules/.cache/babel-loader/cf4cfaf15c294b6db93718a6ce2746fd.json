{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"D:/Poject-main/Poject-main/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"D:/Poject-main/Poject-main/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _require = require('ipld-dag-pb'),\n    DAGNode = _require.DAGNode,\n    DAGLink = _require.DAGLink;\n\nvar CID = require('cids');\n\nvar log = require('debug')('ipfs:mfs:core:utils:add-link');\n\nvar UnixFS = require('ipfs-unixfs');\n\nvar DirSharded = require('ipfs-unixfs-importer/src/dir-sharded');\n\nvar _require2 = require('./hamt-utils'),\n    updateHamtDirectory = _require2.updateHamtDirectory,\n    recreateHamtLevel = _require2.recreateHamtLevel,\n    createShard = _require2.createShard,\n    toPrefix = _require2.toPrefix,\n    addLinksToHamtBucket = _require2.addLinksToHamtBucket;\n\nvar errCode = require('err-code');\n\nvar mc = require('multicodec');\n\nvar mh = require('multihashes');\n\nvar last = require('async-iterator-last');\n\nvar addLink = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(context, options) {\n    var meta;\n    return _regeneratorRuntime.wrap(function _callee$(_context) {\n      while (1) {\n        switch (_context.prev = _context.next) {\n          case 0:\n            if (!(!options.parentCid && !options.parent)) {\n              _context.next = 2;\n              break;\n            }\n\n            throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT');\n\n          case 2:\n            if (!(options.parentCid && !CID.isCID(options.parentCid))) {\n              _context.next = 4;\n              break;\n            }\n\n            throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID');\n\n          case 4:\n            if (options.parent) {\n              _context.next = 9;\n              break;\n            }\n\n            log(\"Loading parent node \".concat(options.parentCid));\n            _context.next = 8;\n            return context.ipld.get(options.parentCid);\n\n          case 8:\n            options.parent = _context.sent;\n\n          case 9:\n            if (options.cid) {\n              _context.next = 11;\n              break;\n            }\n\n            throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID');\n\n          case 11:\n            if (options.name) {\n              _context.next = 13;\n              break;\n            }\n\n            throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME');\n\n          case 13:\n            if (!CID.isCID(options.cid)) {\n              options.cid = new CID(options.cid);\n            }\n\n            if (!(!options.size && options.size !== 0)) {\n              _context.next = 16;\n              break;\n            }\n\n            throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE');\n\n          case 16:\n            meta = UnixFS.unmarshal(options.parent.Data);\n\n            if (!(meta.type === 'hamt-sharded-directory')) {\n              _context.next = 20;\n              break;\n            }\n\n            log('Adding link to sharded directory');\n            return _context.abrupt(\"return\", addToShardedDirectory(context, options));\n\n          case 20:\n            if (!(options.parent.Links.length >= options.shardSplitThreshold)) {\n              _context.next = 23;\n              break;\n            }\n\n            log('Converting directory to sharded directory');\n            return _context.abrupt(\"return\", convertToShardedDirectory(context, options));\n\n          case 23:\n            log(\"Adding \".concat(options.name, \" (\").concat(options.cid, \") to regular directory\"));\n            return _context.abrupt(\"return\", addToDirectory(context, options));\n\n          case 25:\n          case \"end\":\n            return _context.stop();\n        }\n      }\n    }, _callee);\n  }));\n\n  return function addLink(_x, _x2) {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nvar convertToShardedDirectory = /*#__PURE__*/function () {\n  var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(context, options) {\n    var result;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return createShard(context, options.parent.Links.map(function (link) {\n              return {\n                name: link.Name,\n                size: link.Tsize,\n                cid: link.Hash\n              };\n            }).concat({\n              name: options.name,\n              size: options.size,\n              cid: options.cid\n            }), options);\n\n          case 2:\n            result = _context2.sent;\n            log(\"Converted directory to sharded directory \".concat(result.cid));\n            return _context2.abrupt(\"return\", result);\n\n          case 5:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function convertToShardedDirectory(_x3, _x4) {\n    return _ref2.apply(this, arguments);\n  };\n}();\n\nvar addToDirectory = /*#__PURE__*/function () {\n  var _ref3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(context, options) {\n    var parent, format, hashAlg, cid;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            _context3.next = 2;\n            return DAGNode.rmLink(options.parent, options.name);\n\n          case 2:\n            parent = _context3.sent;\n            _context3.next = 5;\n            return DAGNode.addLink(parent, new DAGLink(options.name, options.size, options.cid));\n\n          case 5:\n            parent = _context3.sent;\n            format = mc[options.format.toUpperCase().replace(/-/g, '_')];\n            hashAlg = mh.names[options.hashAlg]; // Persist the new parent DAGNode\n\n            _context3.next = 10;\n            return context.ipld.put(parent, format, {\n              cidVersion: options.cidVersion,\n              hashAlg: hashAlg,\n              hashOnly: !options.flush\n            });\n\n          case 10:\n            cid = _context3.sent;\n            return _context3.abrupt(\"return\", {\n              node: parent,\n              cid: cid\n            });\n\n          case 12:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n\n  return function addToDirectory(_x5, _x6) {\n    return _ref3.apply(this, arguments);\n  };\n}();\n\nvar addToShardedDirectory = /*#__PURE__*/function () {\n  var _ref4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(context, options) {\n    var _yield$addFileToShard, shard, path, result, oldLink, newLink, parent;\n\n    return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            _context4.next = 2;\n            return addFileToShardedDirectory(context, options);\n\n          case 2:\n            _yield$addFileToShard = _context4.sent;\n            shard = _yield$addFileToShard.shard;\n            path = _yield$addFileToShard.path;\n            _context4.next = 7;\n            return last(shard.flush('', context.ipld));\n\n          case 7:\n            result = _context4.sent;\n            // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n            oldLink = options.parent.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n            newLink = result.node.Links.find(function (link) {\n              return link.Name.substring(0, 2) === path[0].prefix;\n            });\n            parent = options.parent;\n\n            if (!oldLink) {\n              _context4.next = 15;\n              break;\n            }\n\n            _context4.next = 14;\n            return DAGNode.rmLink(options.parent, oldLink.Name);\n\n          case 14:\n            parent = _context4.sent;\n\n          case 15:\n            _context4.next = 17;\n            return DAGNode.addLink(parent, newLink);\n\n          case 17:\n            parent = _context4.sent;\n            return _context4.abrupt(\"return\", updateHamtDirectory(context, parent.Links, path[0].bucket, options));\n\n          case 19:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee4);\n  }));\n\n  return function addToShardedDirectory(_x7, _x8) {\n    return _ref4.apply(this, arguments);\n  };\n}();\n\nvar addFileToShardedDirectory = /*#__PURE__*/function () {\n  var _ref5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(context, options) {\n    var file, rootBucket, shard, position, path, index, _loop, _ret;\n\n    return _regeneratorRuntime.wrap(function _callee5$(_context6) {\n      while (1) {\n        switch (_context6.prev = _context6.next) {\n          case 0:\n            file = {\n              name: options.name,\n              cid: options.cid,\n              size: options.size\n            }; // start at the root bucket and descend, loading nodes as we go\n\n            _context6.next = 3;\n            return recreateHamtLevel(options.parent.Links);\n\n          case 3:\n            rootBucket = _context6.sent;\n            shard = new DirSharded({\n              root: true,\n              dir: true,\n              parent: null,\n              parentKey: null,\n              path: '',\n              dirty: true,\n              flat: false\n            }, options);\n            shard._bucket = rootBucket; // load subshards until the bucket & position no longer changes\n\n            _context6.next = 8;\n            return rootBucket._findNewBucketAndPos(file.name);\n\n          case 8:\n            position = _context6.sent;\n            path = toBucketPath(position);\n            path[0].node = options.parent;\n            index = 0;\n            _loop = /*#__PURE__*/_regeneratorRuntime.mark(function _loop() {\n              var segment, node, link, subShard, _position, nextSegment;\n\n              return _regeneratorRuntime.wrap(function _loop$(_context5) {\n                while (1) {\n                  switch (_context5.prev = _context5.next) {\n                    case 0:\n                      segment = path[index];\n                      index++;\n                      node = segment.node;\n                      link = node.Links.find(function (link) {\n                        return link.Name.substring(0, 2) === segment.prefix;\n                      });\n\n                      if (link) {\n                        _context5.next = 8;\n                        break;\n                      }\n\n                      // prefix is new, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be added\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 8:\n                      if (!(link.Name === \"\".concat(segment.prefix).concat(file.name))) {\n                        _context5.next = 12;\n                        break;\n                      }\n\n                      // file already existed, file will be added to the current bucket\n                      log(\"Link \".concat(segment.prefix).concat(file.name, \" will be replaced\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 12:\n                      if (!(link.Name.length > 2)) {\n                        _context5.next = 16;\n                        break;\n                      }\n\n                      // another file had the same prefix, will be replaced with a subshard\n                      log(\"Link \".concat(link.Name, \" will be replaced with a subshard\"));\n                      index = path.length;\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 16:\n                      // load sub-shard\n                      log(\"Found subshard \".concat(segment.prefix));\n                      _context5.next = 19;\n                      return context.ipld.get(link.Hash);\n\n                    case 19:\n                      subShard = _context5.sent;\n\n                      if (path[index]) {\n                        _context5.next = 29;\n                        break;\n                      }\n\n                      log(\"Loaded new subshard \".concat(segment.prefix));\n                      _context5.next = 24;\n                      return recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16));\n\n                    case 24:\n                      _context5.next = 26;\n                      return rootBucket._findNewBucketAndPos(file.name);\n\n                    case 26:\n                      _position = _context5.sent;\n                      path.push({\n                        bucket: _position.bucket,\n                        prefix: toPrefix(_position.pos),\n                        node: subShard\n                      });\n                      return _context5.abrupt(\"return\", \"break\");\n\n                    case 29:\n                      nextSegment = path[index]; // add next level's worth of links to bucket\n\n                      _context5.next = 32;\n                      return addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket);\n\n                    case 32:\n                      nextSegment.node = subShard;\n\n                    case 33:\n                    case \"end\":\n                      return _context5.stop();\n                  }\n                }\n              }, _loop);\n            });\n\n          case 13:\n            if (!(index < path.length)) {\n              _context6.next = 20;\n              break;\n            }\n\n            return _context6.delegateYield(_loop(), \"t0\", 15);\n\n          case 15:\n            _ret = _context6.t0;\n\n            if (!(_ret === \"break\")) {\n              _context6.next = 18;\n              break;\n            }\n\n            return _context6.abrupt(\"break\", 20);\n\n          case 18:\n            _context6.next = 13;\n            break;\n\n          case 20:\n            _context6.next = 22;\n            return shard._bucket.put(file.name, {\n              size: file.size,\n              cid: file.cid\n            });\n\n          case 22:\n            return _context6.abrupt(\"return\", {\n              shard: shard,\n              path: path\n            });\n\n          case 23:\n          case \"end\":\n            return _context6.stop();\n        }\n      }\n    }, _callee5);\n  }));\n\n  return function addFileToShardedDirectory(_x9, _x10) {\n    return _ref5.apply(this, arguments);\n  };\n}();\n\nvar toBucketPath = function toBucketPath(position) {\n  var bucket = position.bucket;\n  var positionInBucket = position.pos;\n  var path = [{\n    bucket: bucket,\n    prefix: toPrefix(positionInBucket)\n  }];\n  bucket = position.bucket._parent;\n  positionInBucket = position.bucket._posAtParent;\n\n  while (bucket) {\n    path.push({\n      bucket: bucket,\n      prefix: toPrefix(positionInBucket)\n    });\n    positionInBucket = bucket._posAtParent;\n    bucket = bucket._parent;\n  }\n\n  path.reverse();\n  return path;\n};\n\nmodule.exports = addLink;","map":{"version":3,"sources":["D:/Poject-main/Poject-main/client/node_modules/ipfs-mfs/src/core/utils/add-link.js"],"names":["require","DAGNode","DAGLink","CID","log","UnixFS","DirSharded","updateHamtDirectory","recreateHamtLevel","createShard","toPrefix","addLinksToHamtBucket","errCode","mc","mh","last","addLink","context","options","parentCid","parent","Error","isCID","ipld","get","cid","name","size","meta","unmarshal","Data","type","addToShardedDirectory","Links","length","shardSplitThreshold","convertToShardedDirectory","addToDirectory","map","link","Name","Tsize","Hash","concat","result","rmLink","format","toUpperCase","replace","hashAlg","names","put","cidVersion","hashOnly","flush","node","addFileToShardedDirectory","shard","path","oldLink","find","substring","prefix","newLink","bucket","file","rootBucket","root","dir","parentKey","dirty","flat","_bucket","_findNewBucketAndPos","position","toBucketPath","index","segment","subShard","parseInt","push","pos","nextSegment","positionInBucket","_parent","_posAtParent","reverse","module","exports"],"mappings":"AAAA;;;;;;AAEA,eAGIA,OAAO,CAAC,aAAD,CAHX;AAAA,IACEC,OADF,YACEA,OADF;AAAA,IAEEC,OAFF,YAEEA,OAFF;;AAIA,IAAMC,GAAG,GAAGH,OAAO,CAAC,MAAD,CAAnB;;AACA,IAAMI,GAAG,GAAGJ,OAAO,CAAC,OAAD,CAAP,CAAiB,8BAAjB,CAAZ;;AACA,IAAMK,MAAM,GAAGL,OAAO,CAAC,aAAD,CAAtB;;AACA,IAAMM,UAAU,GAAGN,OAAO,CAAC,sCAAD,CAA1B;;AACA,gBAMIA,OAAO,CAAC,cAAD,CANX;AAAA,IACEO,mBADF,aACEA,mBADF;AAAA,IAEEC,iBAFF,aAEEA,iBAFF;AAAA,IAGEC,WAHF,aAGEA,WAHF;AAAA,IAIEC,QAJF,aAIEA,QAJF;AAAA,IAKEC,oBALF,aAKEA,oBALF;;AAOA,IAAMC,OAAO,GAAGZ,OAAO,CAAC,UAAD,CAAvB;;AACA,IAAMa,EAAE,GAAGb,OAAO,CAAC,YAAD,CAAlB;;AACA,IAAMc,EAAE,GAAGd,OAAO,CAAC,aAAD,CAAlB;;AACA,IAAMe,IAAI,GAAGf,OAAO,CAAC,qBAAD,CAApB;;AAEA,IAAMgB,OAAO;AAAA,sEAAG,iBAAOC,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACV,CAACA,OAAO,CAACC,SAAT,IAAsB,CAACD,OAAO,CAACE,MADrB;AAAA;AAAA;AAAA;;AAAA,kBAENR,OAAO,CAAC,IAAIS,KAAJ,CAAU,yCAAV,CAAD,EAAuD,gBAAvD,CAFD;;AAAA;AAAA,kBAKVH,OAAO,CAACC,SAAR,IAAqB,CAAChB,GAAG,CAACmB,KAAJ,CAAUJ,OAAO,CAACC,SAAlB,CALZ;AAAA;AAAA;AAAA;;AAAA,kBAMNP,OAAO,CAAC,IAAIS,KAAJ,CAAU,+BAAV,CAAD,EAA6C,mBAA7C,CAND;;AAAA;AAAA,gBASTH,OAAO,CAACE,MATC;AAAA;AAAA;AAAA;;AAUZhB,YAAAA,GAAG,+BAAwBc,OAAO,CAACC,SAAhC,EAAH;AAVY;AAAA,mBAYWF,OAAO,CAACM,IAAR,CAAaC,GAAb,CAAiBN,OAAO,CAACC,SAAzB,CAZX;;AAAA;AAYZD,YAAAA,OAAO,CAACE,MAZI;;AAAA;AAAA,gBAeTF,OAAO,CAACO,GAfC;AAAA;AAAA;AAAA;;AAAA,kBAgBNb,OAAO,CAAC,IAAIS,KAAJ,CAAU,gCAAV,CAAD,EAA8C,kBAA9C,CAhBD;;AAAA;AAAA,gBAmBTH,OAAO,CAACQ,IAnBC;AAAA;AAAA;AAAA;;AAAA,kBAoBNd,OAAO,CAAC,IAAIS,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CApBD;;AAAA;AAuBd,gBAAI,CAAClB,GAAG,CAACmB,KAAJ,CAAUJ,OAAO,CAACO,GAAlB,CAAL,EAA6B;AAC3BP,cAAAA,OAAO,CAACO,GAAR,GAAc,IAAItB,GAAJ,CAAQe,OAAO,CAACO,GAAhB,CAAd;AACD;;AAzBa,kBA2BV,CAACP,OAAO,CAACS,IAAT,IAAiBT,OAAO,CAACS,IAAR,KAAiB,CA3BxB;AAAA;AAAA;AAAA;;AAAA,kBA4BNf,OAAO,CAAC,IAAIS,KAAJ,CAAU,iCAAV,CAAD,EAA+C,mBAA/C,CA5BD;;AAAA;AA+BRO,YAAAA,IA/BQ,GA+BDvB,MAAM,CAACwB,SAAP,CAAiBX,OAAO,CAACE,MAAR,CAAeU,IAAhC,CA/BC;;AAAA,kBAiCVF,IAAI,CAACG,IAAL,KAAc,wBAjCJ;AAAA;AAAA;AAAA;;AAkCZ3B,YAAAA,GAAG,CAAC,kCAAD,CAAH;AAlCY,6CAoCL4B,qBAAqB,CAACf,OAAD,EAAUC,OAAV,CApChB;;AAAA;AAAA,kBAuCVA,OAAO,CAACE,MAAR,CAAea,KAAf,CAAqBC,MAArB,IAA+BhB,OAAO,CAACiB,mBAvC7B;AAAA;AAAA;AAAA;;AAwCZ/B,YAAAA,GAAG,CAAC,2CAAD,CAAH;AAxCY,6CA0CLgC,yBAAyB,CAACnB,OAAD,EAAUC,OAAV,CA1CpB;;AAAA;AA6Cdd,YAAAA,GAAG,kBAAWc,OAAO,CAACQ,IAAnB,eAA4BR,OAAO,CAACO,GAApC,4BAAH;AA7Cc,6CA+CPY,cAAc,CAACpB,OAAD,EAAUC,OAAV,CA/CP;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAPF,OAAO;AAAA;AAAA;AAAA,GAAb;;AAkDA,IAAMoB,yBAAyB;AAAA,uEAAG,kBAAOnB,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACXT,WAAW,CAACQ,OAAD,EAAUC,OAAO,CAACE,MAAR,CAAea,KAAf,CAAqBK,GAArB,CAAyB,UAAAC,IAAI;AAAA,qBAAK;AAC1Eb,gBAAAA,IAAI,EAAEa,IAAI,CAACC,IAD+D;AAE1Eb,gBAAAA,IAAI,EAAEY,IAAI,CAACE,KAF+D;AAG1EhB,gBAAAA,GAAG,EAAEc,IAAI,CAACG;AAHgE,eAAL;AAAA,aAA7B,EAItCC,MAJsC,CAI/B;AACTjB,cAAAA,IAAI,EAAER,OAAO,CAACQ,IADL;AAETC,cAAAA,IAAI,EAAET,OAAO,CAACS,IAFL;AAGTF,cAAAA,GAAG,EAAEP,OAAO,CAACO;AAHJ,aAJ+B,CAAV,EAQ5BP,OAR4B,CADA;;AAAA;AAC1B0B,YAAAA,MAD0B;AAWhCxC,YAAAA,GAAG,oDAA6CwC,MAAM,CAACnB,GAApD,EAAH;AAXgC,8CAazBmB,MAbyB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAzBR,yBAAyB;AAAA;AAAA;AAAA,GAA/B;;AAgBA,IAAMC,cAAc;AAAA,uEAAG,kBAAOpB,OAAP,EAAgBC,OAAhB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBACFjB,OAAO,CAAC4C,MAAR,CAAe3B,OAAO,CAACE,MAAvB,EAA+BF,OAAO,CAACQ,IAAvC,CADE;;AAAA;AACjBN,YAAAA,MADiB;AAAA;AAAA,mBAENnB,OAAO,CAACe,OAAR,CAAgBI,MAAhB,EAAwB,IAAIlB,OAAJ,CAAYgB,OAAO,CAACQ,IAApB,EAA0BR,OAAO,CAACS,IAAlC,EAAwCT,OAAO,CAACO,GAAhD,CAAxB,CAFM;;AAAA;AAErBL,YAAAA,MAFqB;AAIf0B,YAAAA,MAJe,GAINjC,EAAE,CAACK,OAAO,CAAC4B,MAAR,CAAeC,WAAf,GAA6BC,OAA7B,CAAqC,IAArC,EAA2C,GAA3C,CAAD,CAJI;AAKfC,YAAAA,OALe,GAKLnC,EAAE,CAACoC,KAAH,CAAShC,OAAO,CAAC+B,OAAjB,CALK,EAOrB;;AAPqB;AAAA,mBAQHhC,OAAO,CAACM,IAAR,CAAa4B,GAAb,CAAiB/B,MAAjB,EAAyB0B,MAAzB,EAAiC;AACjDM,cAAAA,UAAU,EAAElC,OAAO,CAACkC,UAD6B;AAEjDH,cAAAA,OAAO,EAAPA,OAFiD;AAGjDI,cAAAA,QAAQ,EAAE,CAACnC,OAAO,CAACoC;AAH8B,aAAjC,CARG;;AAAA;AAQf7B,YAAAA,GARe;AAAA,8CAcd;AACL8B,cAAAA,IAAI,EAAEnC,MADD;AAELK,cAAAA,GAAG,EAAHA;AAFK,aAdc;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAdY,cAAc;AAAA;AAAA;AAAA,GAApB;;AAoBA,IAAML,qBAAqB;AAAA,uEAAG,kBAAOf,OAAP,EAAgBC,OAAhB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAGlBsC,yBAAyB,CAACvC,OAAD,EAAUC,OAAV,CAHP;;AAAA;AAAA;AAE1BuC,YAAAA,KAF0B,yBAE1BA,KAF0B;AAEnBC,YAAAA,IAFmB,yBAEnBA,IAFmB;AAAA;AAAA,mBAKP3C,IAAI,CAAC0C,KAAK,CAACH,KAAN,CAAY,EAAZ,EAAgBrC,OAAO,CAACM,IAAxB,CAAD,CALG;;AAAA;AAKtBqB,YAAAA,MALsB;AAO5B;AACMe,YAAAA,OARsB,GAQZzC,OAAO,CAACE,MAAR,CAAea,KAAf,CACb2B,IADa,CACR,UAAArB,IAAI;AAAA,qBAAIA,IAAI,CAACC,IAAL,CAAUqB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BH,IAAI,CAAC,CAAD,CAAJ,CAAQI,MAA1C;AAAA,aADI,CARY;AAWtBC,YAAAA,OAXsB,GAWZnB,MAAM,CAACW,IAAP,CAAYtB,KAAZ,CACb2B,IADa,CACR,UAAArB,IAAI;AAAA,qBAAIA,IAAI,CAACC,IAAL,CAAUqB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BH,IAAI,CAAC,CAAD,CAAJ,CAAQI,MAA1C;AAAA,aADI,CAXY;AAcxB1C,YAAAA,MAdwB,GAcfF,OAAO,CAACE,MAdO;;AAAA,iBAgBxBuC,OAhBwB;AAAA;AAAA;AAAA;;AAAA;AAAA,mBAiBX1D,OAAO,CAAC4C,MAAR,CAAe3B,OAAO,CAACE,MAAvB,EAA+BuC,OAAO,CAACnB,IAAvC,CAjBW;;AAAA;AAiB1BpB,YAAAA,MAjB0B;;AAAA;AAAA;AAAA,mBAoBbnB,OAAO,CAACe,OAAR,CAAgBI,MAAhB,EAAwB2C,OAAxB,CApBa;;AAAA;AAoB5B3C,YAAAA,MApB4B;AAAA,8CAsBrBb,mBAAmB,CAACU,OAAD,EAAUG,MAAM,CAACa,KAAjB,EAAwByB,IAAI,CAAC,CAAD,CAAJ,CAAQM,MAAhC,EAAwC9C,OAAxC,CAtBE;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAArBc,qBAAqB;AAAA;AAAA;AAAA,GAA3B;;AAyBA,IAAMwB,yBAAyB;AAAA,uEAAG,kBAAOvC,OAAP,EAAgBC,OAAhB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAC1B+C,YAAAA,IAD0B,GACnB;AACXvC,cAAAA,IAAI,EAAER,OAAO,CAACQ,IADH;AAEXD,cAAAA,GAAG,EAAEP,OAAO,CAACO,GAFF;AAGXE,cAAAA,IAAI,EAAET,OAAO,CAACS;AAHH,aADmB,EAOhC;;AAPgC;AAAA,mBAQPnB,iBAAiB,CAACU,OAAO,CAACE,MAAR,CAAea,KAAhB,CARV;;AAAA;AAQ1BiC,YAAAA,UAR0B;AAU1BT,YAAAA,KAV0B,GAUlB,IAAInD,UAAJ,CAAe;AAC3B6D,cAAAA,IAAI,EAAE,IADqB;AAE3BC,cAAAA,GAAG,EAAE,IAFsB;AAG3BhD,cAAAA,MAAM,EAAE,IAHmB;AAI3BiD,cAAAA,SAAS,EAAE,IAJgB;AAK3BX,cAAAA,IAAI,EAAE,EALqB;AAM3BY,cAAAA,KAAK,EAAE,IANoB;AAO3BC,cAAAA,IAAI,EAAE;AAPqB,aAAf,EAQXrD,OARW,CAVkB;AAmBhCuC,YAAAA,KAAK,CAACe,OAAN,GAAgBN,UAAhB,CAnBgC,CAqBhC;;AArBgC;AAAA,mBAsBTA,UAAU,CAACO,oBAAX,CAAgCR,IAAI,CAACvC,IAArC,CAtBS;;AAAA;AAsB1BgD,YAAAA,QAtB0B;AAuB1BhB,YAAAA,IAvB0B,GAuBnBiB,YAAY,CAACD,QAAD,CAvBO;AAwBhChB,YAAAA,IAAI,CAAC,CAAD,CAAJ,CAAQH,IAAR,GAAerC,OAAO,CAACE,MAAvB;AACIwD,YAAAA,KAzB4B,GAyBpB,CAzBoB;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;AA4B1BC,sBAAAA,OA5B0B,GA4BhBnB,IAAI,CAACkB,KAAD,CA5BY;AA6B9BA,sBAAAA,KAAK;AACDrB,sBAAAA,IA9B0B,GA8BnBsB,OAAO,CAACtB,IA9BW;AAgC1BhB,sBAAAA,IAhC0B,GAgCnBgB,IAAI,CAACtB,KAAL,CACR2B,IADQ,CACH,UAAArB,IAAI;AAAA,+BAAIA,IAAI,CAACC,IAAL,CAAUqB,SAAV,CAAoB,CAApB,EAAuB,CAAvB,MAA8BgB,OAAO,CAACf,MAA1C;AAAA,uBADD,CAhCmB;;AAAA,0BAmCzBvB,IAnCyB;AAAA;AAAA;AAAA;;AAoC5B;AACAnC,sBAAAA,GAAG,gBAASyE,OAAO,CAACf,MAAjB,SAA0BG,IAAI,CAACvC,IAA/B,oBAAH;AACAkD,sBAAAA,KAAK,GAAGlB,IAAI,CAACxB,MAAb;AAtC4B;;AAAA;AAAA,4BA2C1BK,IAAI,CAACC,IAAL,eAAiBqC,OAAO,CAACf,MAAzB,SAAkCG,IAAI,CAACvC,IAAvC,CA3C0B;AAAA;AAAA;AAAA;;AA4C5B;AACAtB,sBAAAA,GAAG,gBAASyE,OAAO,CAACf,MAAjB,SAA0BG,IAAI,CAACvC,IAA/B,uBAAH;AACAkD,sBAAAA,KAAK,GAAGlB,IAAI,CAACxB,MAAb;AA9C4B;;AAAA;AAAA,4BAmD1BK,IAAI,CAACC,IAAL,CAAUN,MAAV,GAAmB,CAnDO;AAAA;AAAA;AAAA;;AAoD5B;AACA9B,sBAAAA,GAAG,gBAASmC,IAAI,CAACC,IAAd,uCAAH;AACAoC,sBAAAA,KAAK,GAAGlB,IAAI,CAACxB,MAAb;AAtD4B;;AAAA;AA2D9B;AACA9B,sBAAAA,GAAG,0BAAmByE,OAAO,CAACf,MAA3B,EAAH;AA5D8B;AAAA,6BA6DP7C,OAAO,CAACM,IAAR,CAAaC,GAAb,CAAiBe,IAAI,CAACG,IAAtB,CA7DO;;AAAA;AA6DxBoC,sBAAAA,QA7DwB;;AAAA,0BAgEzBpB,IAAI,CAACkB,KAAD,CAhEqB;AAAA;AAAA;AAAA;;AAiE5BxE,sBAAAA,GAAG,+BAAwByE,OAAO,CAACf,MAAhC,EAAH;AAjE4B;AAAA,6BAkEtBtD,iBAAiB,CAACsE,QAAQ,CAAC7C,KAAV,EAAiBiC,UAAjB,EAA6BW,OAAO,CAACb,MAArC,EAA6Ce,QAAQ,CAACF,OAAO,CAACf,MAAT,EAAiB,EAAjB,CAArD,CAlEK;;AAAA;AAAA;AAAA,6BAoELI,UAAU,CAACO,oBAAX,CAAgCR,IAAI,CAACvC,IAArC,CApEK;;AAAA;AAoEtBgD,sBAAAA,SApEsB;AAsE5BhB,sBAAAA,IAAI,CAACsB,IAAL,CAAU;AACRhB,wBAAAA,MAAM,EAAEU,SAAQ,CAACV,MADT;AAERF,wBAAAA,MAAM,EAAEpD,QAAQ,CAACgE,SAAQ,CAACO,GAAV,CAFR;AAGR1B,wBAAAA,IAAI,EAAEuB;AAHE,uBAAV;AAtE4B;;AAAA;AA+ExBI,sBAAAA,WA/EwB,GA+EVxB,IAAI,CAACkB,KAAD,CA/EM,EAiF9B;;AAjF8B;AAAA,6BAkFxBjE,oBAAoB,CAACmE,QAAQ,CAAC7C,KAAV,EAAiBiD,WAAW,CAAClB,MAA7B,EAAqCE,UAArC,CAlFI;;AAAA;AAoF9BgB,sBAAAA,WAAW,CAAC3B,IAAZ,GAAmBuB,QAAnB;;AApF8B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;;AAAA;AAAA,kBA2BzBF,KAAK,GAAGlB,IAAI,CAACxB,MA3BY;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;;AAAA;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;;AAAA;AAAA;AAAA,mBAwF1BuB,KAAK,CAACe,OAAN,CAAcrB,GAAd,CAAkBc,IAAI,CAACvC,IAAvB,EAA6B;AACjCC,cAAAA,IAAI,EAAEsC,IAAI,CAACtC,IADsB;AAEjCF,cAAAA,GAAG,EAAEwC,IAAI,CAACxC;AAFuB,aAA7B,CAxF0B;;AAAA;AAAA,8CA6FzB;AACLgC,cAAAA,KAAK,EAALA,KADK;AACEC,cAAAA,IAAI,EAAJA;AADF,aA7FyB;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAzBF,yBAAyB;AAAA;AAAA;AAAA,GAA/B;;AAkGA,IAAMmB,YAAY,GAAG,SAAfA,YAAe,CAACD,QAAD,EAAc;AACjC,MAAIV,MAAM,GAAGU,QAAQ,CAACV,MAAtB;AACA,MAAImB,gBAAgB,GAAGT,QAAQ,CAACO,GAAhC;AACA,MAAIvB,IAAI,GAAG,CAAC;AACVM,IAAAA,MAAM,EAANA,MADU;AAEVF,IAAAA,MAAM,EAAEpD,QAAQ,CAACyE,gBAAD;AAFN,GAAD,CAAX;AAKAnB,EAAAA,MAAM,GAAGU,QAAQ,CAACV,MAAT,CAAgBoB,OAAzB;AACAD,EAAAA,gBAAgB,GAAGT,QAAQ,CAACV,MAAT,CAAgBqB,YAAnC;;AAEA,SAAOrB,MAAP,EAAe;AACbN,IAAAA,IAAI,CAACsB,IAAL,CAAU;AACRhB,MAAAA,MAAM,EAANA,MADQ;AAERF,MAAAA,MAAM,EAAEpD,QAAQ,CAACyE,gBAAD;AAFR,KAAV;AAKAA,IAAAA,gBAAgB,GAAGnB,MAAM,CAACqB,YAA1B;AACArB,IAAAA,MAAM,GAAGA,MAAM,CAACoB,OAAhB;AACD;;AAED1B,EAAAA,IAAI,CAAC4B,OAAL;AAEA,SAAO5B,IAAP;AACD,CAxBD;;AA0BA6B,MAAM,CAACC,OAAP,GAAiBxE,OAAjB","sourcesContent":["'use strict'\n\nconst {\n  DAGNode,\n  DAGLink\n} = require('ipld-dag-pb')\nconst CID = require('cids')\nconst log = require('debug')('ipfs:mfs:core:utils:add-link')\nconst UnixFS = require('ipfs-unixfs')\nconst DirSharded = require('ipfs-unixfs-importer/src/dir-sharded')\nconst {\n  updateHamtDirectory,\n  recreateHamtLevel,\n  createShard,\n  toPrefix,\n  addLinksToHamtBucket\n} = require('./hamt-utils')\nconst errCode = require('err-code')\nconst mc = require('multicodec')\nconst mh = require('multihashes')\nconst last = require('async-iterator-last')\n\nconst addLink = async (context, options) => {\n  if (!options.parentCid && !options.parent) {\n    throw errCode(new Error('No parent node or CID passed to addLink'), 'EINVALIDPARENT')\n  }\n\n  if (options.parentCid && !CID.isCID(options.parentCid)) {\n    throw errCode(new Error('Invalid CID passed to addLink'), 'EINVALIDPARENTCID')\n  }\n\n  if (!options.parent) {\n    log(`Loading parent node ${options.parentCid}`)\n\n    options.parent = await context.ipld.get(options.parentCid)\n  }\n\n  if (!options.cid) {\n    throw errCode(new Error('No child cid passed to addLink'), 'EINVALIDCHILDCID')\n  }\n\n  if (!options.name) {\n    throw errCode(new Error('No child name passed to addLink'), 'EINVALIDCHILDNAME')\n  }\n\n  if (!CID.isCID(options.cid)) {\n    options.cid = new CID(options.cid)\n  }\n\n  if (!options.size && options.size !== 0) {\n    throw errCode(new Error('No child size passed to addLink'), 'EINVALIDCHILDSIZE')\n  }\n\n  const meta = UnixFS.unmarshal(options.parent.Data)\n\n  if (meta.type === 'hamt-sharded-directory') {\n    log('Adding link to sharded directory')\n\n    return addToShardedDirectory(context, options)\n  }\n\n  if (options.parent.Links.length >= options.shardSplitThreshold) {\n    log('Converting directory to sharded directory')\n\n    return convertToShardedDirectory(context, options)\n  }\n\n  log(`Adding ${options.name} (${options.cid}) to regular directory`)\n\n  return addToDirectory(context, options)\n}\n\nconst convertToShardedDirectory = async (context, options) => {\n  const result = await createShard(context, options.parent.Links.map(link => ({\n    name: link.Name,\n    size: link.Tsize,\n    cid: link.Hash\n  })).concat({\n    name: options.name,\n    size: options.size,\n    cid: options.cid\n  }), options)\n\n  log(`Converted directory to sharded directory ${result.cid}`)\n\n  return result\n}\n\nconst addToDirectory = async (context, options) => {\n  let parent = await DAGNode.rmLink(options.parent, options.name)\n  parent = await DAGNode.addLink(parent, new DAGLink(options.name, options.size, options.cid))\n\n  const format = mc[options.format.toUpperCase().replace(/-/g, '_')]\n  const hashAlg = mh.names[options.hashAlg]\n\n  // Persist the new parent DAGNode\n  const cid = await context.ipld.put(parent, format, {\n    cidVersion: options.cidVersion,\n    hashAlg,\n    hashOnly: !options.flush\n  })\n\n  return {\n    node: parent,\n    cid\n  }\n}\n\nconst addToShardedDirectory = async (context, options) => {\n  const {\n    shard, path\n  } = await addFileToShardedDirectory(context, options)\n\n  const result = await last(shard.flush('', context.ipld))\n\n  // we have written out the shard, but only one sub-shard will have been written so replace it in the original shard\n  const oldLink = options.parent.Links\n    .find(link => link.Name.substring(0, 2) === path[0].prefix)\n\n  const newLink = result.node.Links\n    .find(link => link.Name.substring(0, 2) === path[0].prefix)\n\n  let parent = options.parent\n\n  if (oldLink) {\n    parent = await DAGNode.rmLink(options.parent, oldLink.Name)\n  }\n\n  parent = await DAGNode.addLink(parent, newLink)\n\n  return updateHamtDirectory(context, parent.Links, path[0].bucket, options)\n}\n\nconst addFileToShardedDirectory = async (context, options) => {\n  const file = {\n    name: options.name,\n    cid: options.cid,\n    size: options.size\n  }\n\n  // start at the root bucket and descend, loading nodes as we go\n  const rootBucket = await recreateHamtLevel(options.parent.Links)\n\n  const shard = new DirSharded({\n    root: true,\n    dir: true,\n    parent: null,\n    parentKey: null,\n    path: '',\n    dirty: true,\n    flat: false\n  }, options)\n  shard._bucket = rootBucket\n\n  // load subshards until the bucket & position no longer changes\n  const position = await rootBucket._findNewBucketAndPos(file.name)\n  const path = toBucketPath(position)\n  path[0].node = options.parent\n  let index = 0\n\n  while (index < path.length) {\n    let segment = path[index]\n    index++\n    let node = segment.node\n\n    let link = node.Links\n      .find(link => link.Name.substring(0, 2) === segment.prefix)\n\n    if (!link) {\n      // prefix is new, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be added`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name === `${segment.prefix}${file.name}`) {\n      // file already existed, file will be added to the current bucket\n      log(`Link ${segment.prefix}${file.name} will be replaced`)\n      index = path.length\n\n      break\n    }\n\n    if (link.Name.length > 2) {\n      // another file had the same prefix, will be replaced with a subshard\n      log(`Link ${link.Name} will be replaced with a subshard`)\n      index = path.length\n\n      break\n    }\n\n    // load sub-shard\n    log(`Found subshard ${segment.prefix}`)\n    const subShard = await context.ipld.get(link.Hash)\n\n    // subshard hasn't been loaded, descend to the next level of the HAMT\n    if (!path[index]) {\n      log(`Loaded new subshard ${segment.prefix}`)\n      await recreateHamtLevel(subShard.Links, rootBucket, segment.bucket, parseInt(segment.prefix, 16))\n\n      const position = await rootBucket._findNewBucketAndPos(file.name)\n\n      path.push({\n        bucket: position.bucket,\n        prefix: toPrefix(position.pos),\n        node: subShard\n      })\n\n      break\n    }\n\n    const nextSegment = path[index]\n\n    // add next level's worth of links to bucket\n    await addLinksToHamtBucket(subShard.Links, nextSegment.bucket, rootBucket)\n\n    nextSegment.node = subShard\n  }\n\n  // finally add the new file into the shard\n  await shard._bucket.put(file.name, {\n    size: file.size,\n    cid: file.cid\n  })\n\n  return {\n    shard, path\n  }\n}\n\nconst toBucketPath = (position) => {\n  let bucket = position.bucket\n  let positionInBucket = position.pos\n  let path = [{\n    bucket,\n    prefix: toPrefix(positionInBucket)\n  }]\n\n  bucket = position.bucket._parent\n  positionInBucket = position.bucket._posAtParent\n\n  while (bucket) {\n    path.push({\n      bucket,\n      prefix: toPrefix(positionInBucket)\n    })\n\n    positionInBucket = bucket._posAtParent\n    bucket = bucket._parent\n  }\n\n  path.reverse()\n\n  return path\n}\n\nmodule.exports = addLink\n"]},"metadata":{},"sourceType":"script"}