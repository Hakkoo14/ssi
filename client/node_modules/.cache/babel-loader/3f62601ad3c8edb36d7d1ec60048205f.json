{"ast":null,"code":"'use strict';\n\nvar _regeneratorRuntime = require(\"C:/Users/dd/Desktop/Project SSI/Major Project/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\");\n\nvar _asyncToGenerator = require(\"C:/Users/dd/Desktop/Project SSI/Major Project/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/asyncToGenerator\");\n\nvar _classCallCheck = require(\"C:/Users/dd/Desktop/Project SSI/Major Project/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/classCallCheck\");\n\nvar _createClass = require(\"C:/Users/dd/Desktop/Project SSI/Major Project/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/createClass\");\n\nvar queue = require('async/queue');\n\nvar promisify = require('promisify-es6');\n\nvar promiseToCallback = require('promise-to-callback');\n\nvar WorkerQueue = /*#__PURE__*/function () {\n  /**\n   * Creates a new WorkerQueue.\n   *\n   * @param {DHT} dht\n   * @param {Run} run\n   * @param {Object} path\n   * @param {function} log\n   */\n  function WorkerQueue(dht, run, path, log) {\n    _classCallCheck(this, WorkerQueue);\n\n    this.dht = dht;\n    this.run = run;\n    this.path = path;\n    this.log = log;\n    this.concurrency = this.dht.concurrency;\n    this.queue = this.setupQueue(); // a container for resolve/reject functions that will be populated\n    // when execute() is called\n\n    this.execution = null;\n  }\n  /**\n   * Create the underlying async queue.\n   *\n   * @returns {Object}\n   */\n\n\n  _createClass(WorkerQueue, [{\n    key: \"setupQueue\",\n    value: function setupQueue() {\n      var _this = this;\n\n      var q = queue(function (peer, cb) {\n        promiseToCallback(_this.processNext(peer))(cb);\n      }, this.concurrency); // If there's an error, stop the worker\n\n      q.error = function (err) {\n        _this.log.error('queue', err);\n\n        _this.stop(err);\n      }; // When all peers in the queue have been processed, stop the worker\n\n\n      q.drain = function () {\n        _this.log('queue:drain');\n\n        _this.stop();\n      }; // When a space opens up in the queue, add some more peers\n\n\n      q.unsaturated = function () {\n        if (_this.running) {\n          _this.fill();\n        }\n      };\n\n      q.buffer = 0;\n      return q;\n    }\n    /**\n     * Stop the worker, optionally providing an error to pass to the worker's\n     * callback.\n     *\n     * @param {Error} err\n     */\n\n  }, {\n    key: \"stop\",\n    value: function stop(err) {\n      if (!this.running) {\n        return;\n      }\n\n      this.running = false;\n      this.queue.kill();\n      this.log('worker:stop, %d workers still running', this.run.workers.filter(function (w) {\n        return w.running;\n      }).length);\n\n      if (err) {\n        this.execution.reject(err);\n      } else {\n        this.execution.resolve();\n      }\n    }\n    /**\n     * Use the queue from async to keep `concurrency` amount items running\n     * per path.\n     *\n     * @return {Promise<void>}\n     */\n\n  }, {\n    key: \"execute\",\n    value: function () {\n      var _execute = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this2 = this;\n\n        var execPromise;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                this.running = true; // store the promise resolution functions to be resolved at end of queue\n\n                this.execution = {};\n                execPromise = new Promise(function (resolve, reject) {\n                  return Object.assign(_this2.execution, {\n                    resolve: resolve,\n                    reject: reject\n                  });\n                }); // start queue\n\n                this.fill(); // await completion\n\n                _context.next = 6;\n                return execPromise;\n\n              case 6:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function execute() {\n        return _execute.apply(this, arguments);\n      }\n\n      return execute;\n    }()\n    /**\n     * Add peers to the worker queue until there are enough to satisfy the\n     * worker queue concurrency.\n     * Note that we don't want to take any more than those required to satisfy\n     * concurrency from the peers-to-query queue, because we always want to\n     * query the closest peers to the key first, and new peers are continously\n     * being added to the peers-to-query queue.\n     */\n\n  }, {\n    key: \"fill\",\n    value: function fill() {\n      // Note:\n      // - queue.running(): number of items that are currently running\n      // - queue.length(): the number of items that are waiting to be run\n      while (this.queue.running() + this.queue.length() < this.concurrency && this.path.peersToQuery.length > 0) {\n        this.queue.push(this.path.peersToQuery.dequeue());\n      }\n    }\n    /**\n     * Process the next peer in the queue\n     *\n     * @param {PeerId} peer\n     * @returns {Promise<void>}\n     */\n\n  }, {\n    key: \"processNext\",\n    value: function () {\n      var _processNext = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(peer) {\n        var continueQuerying, continueQueryingError, state, execError;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                if (this.running) {\n                  _context2.next = 2;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 2:\n                if (!this.run.peersSeen.has(peer)) {\n                  _context2.next = 4;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 4:\n                _context2.prev = 4;\n                _context2.next = 7;\n                return this.run.continueQuerying(this);\n\n              case 7:\n                continueQuerying = _context2.sent;\n                _context2.next = 13;\n                break;\n\n              case 10:\n                _context2.prev = 10;\n                _context2.t0 = _context2[\"catch\"](4);\n                continueQueryingError = _context2.t0;\n\n              case 13:\n                if (this.running) {\n                  _context2.next = 15;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 15:\n                if (!continueQueryingError) {\n                  _context2.next = 17;\n                  break;\n                }\n\n                throw continueQueryingError;\n\n              case 17:\n                if (continueQuerying) {\n                  _context2.next = 20;\n                  break;\n                }\n\n                this.stop();\n                return _context2.abrupt(\"return\");\n\n              case 20:\n                if (!this.run.peersSeen.has(peer)) {\n                  _context2.next = 22;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 22:\n                this.run.peersSeen.add(peer); // Execute the query on the next peer\n\n                this.log('queue:work');\n                _context2.prev = 24;\n                _context2.next = 27;\n                return this.execQuery(peer);\n\n              case 27:\n                state = _context2.sent;\n                _context2.next = 33;\n                break;\n\n              case 30:\n                _context2.prev = 30;\n                _context2.t1 = _context2[\"catch\"](24);\n                execError = _context2.t1;\n\n              case 33:\n                if (this.running) {\n                  _context2.next = 35;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\");\n\n              case 35:\n                this.log('queue:work:done', execError, state);\n\n                if (!execError) {\n                  _context2.next = 38;\n                  break;\n                }\n\n                throw execError;\n\n              case 38:\n                if (!(state && state.queryComplete)) {\n                  _context2.next = 42;\n                  break;\n                }\n\n                this.log('query:complete');\n                this.run.stop();\n                return _context2.abrupt(\"return\");\n\n              case 42:\n                // If path is complete, just stop this worker.\n                // Note: this.stop() kills the queue and resolves execution\n                if (state && state.pathComplete) {\n                  this.stop();\n                }\n\n              case 43:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this, [[4, 10], [24, 30]]);\n      }));\n\n      function processNext(_x) {\n        return _processNext.apply(this, arguments);\n      }\n\n      return processNext;\n    }()\n    /**\n     * Execute a query on the next peer.\n     *\n     * @param {PeerId} peer\n     * @returns {Promise<void>}\n     * @private\n     */\n\n  }, {\n    key: \"execQuery\",\n    value: function () {\n      var _execQuery = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(peer) {\n        var _this3 = this;\n\n        var res, queryError;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                _context4.prev = 0;\n                _context4.next = 3;\n                return this.path.queryFunc(peer);\n\n              case 3:\n                res = _context4.sent;\n                _context4.next = 9;\n                break;\n\n              case 6:\n                _context4.prev = 6;\n                _context4.t0 = _context4[\"catch\"](0);\n                queryError = _context4.t0;\n\n              case 9:\n                if (this.running) {\n                  _context4.next = 11;\n                  break;\n                }\n\n                return _context4.abrupt(\"return\");\n\n              case 11:\n                if (!queryError) {\n                  _context4.next = 14;\n                  break;\n                }\n\n                this.run.errors.push(queryError);\n                return _context4.abrupt(\"return\");\n\n              case 14:\n                _context4.next = 16;\n                return promisify(function (cb) {\n                  return _this3.run.peersQueried.add(peer, cb);\n                })();\n\n              case 16:\n                if (!(res.pathComplete || res.queryComplete)) {\n                  _context4.next = 19;\n                  break;\n                }\n\n                this.path.res = res;\n                return _context4.abrupt(\"return\", {\n                  pathComplete: res.pathComplete,\n                  queryComplete: res.queryComplete\n                });\n\n              case 19:\n                if (!(res.closerPeers && res.closerPeers.length > 0)) {\n                  _context4.next = 22;\n                  break;\n                }\n\n                _context4.next = 22;\n                return Promise.all(res.closerPeers.map( /*#__PURE__*/function () {\n                  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(closer) {\n                    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n                      while (1) {\n                        switch (_context3.prev = _context3.next) {\n                          case 0:\n                            if (!_this3.dht._isSelf(closer.id)) {\n                              _context3.next = 2;\n                              break;\n                            }\n\n                            return _context3.abrupt(\"return\");\n\n                          case 2:\n                            closer = _this3.dht.peerBook.put(closer);\n\n                            _this3.dht._peerDiscovered(closer);\n\n                            _context3.next = 6;\n                            return _this3.path.addPeerToQuery(closer.id);\n\n                          case 6:\n                          case \"end\":\n                            return _context3.stop();\n                        }\n                      }\n                    }, _callee3);\n                  }));\n\n                  return function (_x3) {\n                    return _ref.apply(this, arguments);\n                  };\n                }()));\n\n              case 22:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this, [[0, 6]]);\n      }));\n\n      function execQuery(_x2) {\n        return _execQuery.apply(this, arguments);\n      }\n\n      return execQuery;\n    }()\n  }]);\n\n  return WorkerQueue;\n}();\n\nmodule.exports = WorkerQueue;","map":{"version":3,"sources":["C:/Users/dd/Desktop/Project SSI/Major Project/client/node_modules/libp2p-kad-dht/src/query/workerQueue.js"],"names":["queue","require","promisify","promiseToCallback","WorkerQueue","dht","run","path","log","concurrency","setupQueue","execution","q","peer","cb","processNext","error","err","stop","drain","unsaturated","running","fill","buffer","kill","workers","filter","w","length","reject","resolve","execPromise","Promise","Object","assign","peersToQuery","push","dequeue","peersSeen","has","continueQuerying","continueQueryingError","add","execQuery","state","execError","queryComplete","pathComplete","queryFunc","res","queryError","errors","peersQueried","closerPeers","all","map","closer","_isSelf","id","peerBook","put","_peerDiscovered","addPeerToQuery","module","exports"],"mappings":"AAAA;;;;;;;;;;AAEA,IAAMA,KAAK,GAAGC,OAAO,CAAC,aAAD,CAArB;;AACA,IAAMC,SAAS,GAAGD,OAAO,CAAC,eAAD,CAAzB;;AACA,IAAME,iBAAiB,GAAGF,OAAO,CAAC,qBAAD,CAAjC;;IAEMG,W;AACJ;AACF;AACA;AACA;AACA;AACA;AACA;AACA;AACE,uBAAaC,GAAb,EAAkBC,GAAlB,EAAuBC,IAAvB,EAA6BC,GAA7B,EAAkC;AAAA;;AAChC,SAAKH,GAAL,GAAWA,GAAX;AACA,SAAKC,GAAL,GAAWA,GAAX;AACA,SAAKC,IAAL,GAAYA,IAAZ;AACA,SAAKC,GAAL,GAAWA,GAAX;AAEA,SAAKC,WAAL,GAAmB,KAAKJ,GAAL,CAASI,WAA5B;AACA,SAAKT,KAAL,GAAa,KAAKU,UAAL,EAAb,CAPgC,CAQhC;AACA;;AACA,SAAKC,SAAL,GAAiB,IAAjB;AACD;AAED;AACF;AACA;AACA;AACA;;;;;WACE,sBAAc;AAAA;;AACZ,UAAMC,CAAC,GAAGZ,KAAK,CAAC,UAACa,IAAD,EAAOC,EAAP,EAAc;AAC5BX,QAAAA,iBAAiB,CAAC,KAAI,CAACY,WAAL,CAAiBF,IAAjB,CAAD,CAAjB,CAA0CC,EAA1C;AACD,OAFc,EAEZ,KAAKL,WAFO,CAAf,CADY,CAKZ;;AACAG,MAAAA,CAAC,CAACI,KAAF,GAAU,UAACC,GAAD,EAAS;AACjB,QAAA,KAAI,CAACT,GAAL,CAASQ,KAAT,CAAe,OAAf,EAAwBC,GAAxB;;AACA,QAAA,KAAI,CAACC,IAAL,CAAUD,GAAV;AACD,OAHD,CANY,CAWZ;;;AACAL,MAAAA,CAAC,CAACO,KAAF,GAAU,YAAM;AACd,QAAA,KAAI,CAACX,GAAL,CAAS,aAAT;;AACA,QAAA,KAAI,CAACU,IAAL;AACD,OAHD,CAZY,CAiBZ;;;AACAN,MAAAA,CAAC,CAACQ,WAAF,GAAgB,YAAM;AACpB,YAAI,KAAI,CAACC,OAAT,EAAkB;AAChB,UAAA,KAAI,CAACC,IAAL;AACD;AACF,OAJD;;AAMAV,MAAAA,CAAC,CAACW,MAAF,GAAW,CAAX;AAEA,aAAOX,CAAP;AACD;AAED;AACF;AACA;AACA;AACA;AACA;;;;WACE,cAAMK,GAAN,EAAW;AACT,UAAI,CAAC,KAAKI,OAAV,EAAmB;AACjB;AACD;;AAED,WAAKA,OAAL,GAAe,KAAf;AACA,WAAKrB,KAAL,CAAWwB,IAAX;AACA,WAAKhB,GAAL,CAAS,uCAAT,EAAkD,KAAKF,GAAL,CAASmB,OAAT,CAAiBC,MAAjB,CAAwB,UAAAC,CAAC;AAAA,eAAIA,CAAC,CAACN,OAAN;AAAA,OAAzB,EAAwCO,MAA1F;;AACA,UAAIX,GAAJ,EAAS;AACP,aAAKN,SAAL,CAAekB,MAAf,CAAsBZ,GAAtB;AACD,OAFD,MAEO;AACL,aAAKN,SAAL,CAAemB,OAAf;AACD;AACF;AAED;AACF;AACA;AACA;AACA;AACA;;;;;8EACE;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AACE,qBAAKT,OAAL,GAAe,IAAf,CADF,CAEE;;AACA,qBAAKV,SAAL,GAAiB,EAAjB;AACMoB,gBAAAA,WAJR,GAIsB,IAAIC,OAAJ,CAAY,UAACF,OAAD,EAAUD,MAAV;AAAA,yBAAqBI,MAAM,CAACC,MAAP,CAAc,MAAI,CAACvB,SAAnB,EAA8B;AAAEmB,oBAAAA,OAAO,EAAPA,OAAF;AAAWD,oBAAAA,MAAM,EAANA;AAAX,mBAA9B,CAArB;AAAA,iBAAZ,CAJtB,EAKE;;AACA,qBAAKP,IAAL,GANF,CAOE;;AAPF;AAAA,uBAQQS,WARR;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AAWA;AACF;AACA;AACA;AACA;AACA;AACA;AACA;;;;WACE,gBAAQ;AACN;AACA;AACA;AACA,aAAO,KAAK/B,KAAL,CAAWqB,OAAX,KAAuB,KAAKrB,KAAL,CAAW4B,MAAX,EAAvB,GAA6C,KAAKnB,WAAlD,IACA,KAAKF,IAAL,CAAU4B,YAAV,CAAuBP,MAAvB,GAAgC,CADvC,EAC0C;AACxC,aAAK5B,KAAL,CAAWoC,IAAX,CAAgB,KAAK7B,IAAL,CAAU4B,YAAV,CAAuBE,OAAvB,EAAhB;AACD;AACF;AAED;AACF;AACA;AACA;AACA;AACA;;;;;kFACE,kBAAmBxB,IAAnB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,oBACO,KAAKQ,OADZ;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA,qBAOM,KAAKf,GAAL,CAASgC,SAAT,CAAmBC,GAAnB,CAAuB1B,IAAvB,CAPN;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA;AAAA;AAAA,uBAc6B,KAAKP,GAAL,CAASkC,gBAAT,CAA0B,IAA1B,CAd7B;;AAAA;AAcIA,gBAAAA,gBAdJ;AAAA;AAAA;;AAAA;AAAA;AAAA;AAgBIC,gBAAAA,qBAAqB,eAArB;;AAhBJ;AAAA,oBAoBO,KAAKpB,OApBZ;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA,qBAwBMoB,qBAxBN;AAAA;AAAA;AAAA;;AAAA,sBAyBUA,qBAzBV;;AAAA;AAAA,oBA+BOD,gBA/BP;AAAA;AAAA;AAAA;;AAgCI,qBAAKtB,IAAL;AAhCJ;;AAAA;AAAA,qBAqCM,KAAKZ,GAAL,CAASgC,SAAT,CAAmBC,GAAnB,CAAuB1B,IAAvB,CArCN;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAwCE,qBAAKP,GAAL,CAASgC,SAAT,CAAmBI,GAAnB,CAAuB7B,IAAvB,EAxCF,CA0CE;;AACA,qBAAKL,GAAL,CAAS,YAAT;AA3CF;AAAA;AAAA,uBA8CkB,KAAKmC,SAAL,CAAe9B,IAAf,CA9ClB;;AAAA;AA8CI+B,gBAAAA,KA9CJ;AAAA;AAAA;;AAAA;AAAA;AAAA;AAgDIC,gBAAAA,SAAS,eAAT;;AAhDJ;AAAA,oBAoDO,KAAKxB,OApDZ;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAwDE,qBAAKb,GAAL,CAAS,iBAAT,EAA4BqC,SAA5B,EAAuCD,KAAvC;;AAxDF,qBA0DMC,SA1DN;AAAA;AAAA;AAAA;;AAAA,sBA2DUA,SA3DV;;AAAA;AAAA,sBAiEMD,KAAK,IAAIA,KAAK,CAACE,aAjErB;AAAA;AAAA;AAAA;;AAkEI,qBAAKtC,GAAL,CAAS,gBAAT;AACA,qBAAKF,GAAL,CAASY,IAAT;AAnEJ;;AAAA;AAuEE;AACA;AACA,oBAAI0B,KAAK,IAAIA,KAAK,CAACG,YAAnB,EAAiC;AAC/B,uBAAK7B,IAAL;AACD;;AA3EH;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;AA8EA;AACF;AACA;AACA;AACA;AACA;AACA;;;;;gFACE,kBAAiBL,IAAjB;AAAA;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,uBAGgB,KAAKN,IAAL,CAAUyC,SAAV,CAAoBnC,IAApB,CAHhB;;AAAA;AAGIoC,gBAAAA,GAHJ;AAAA;AAAA;;AAAA;AAAA;AAAA;AAKIC,gBAAAA,UAAU,eAAV;;AALJ;AAAA,oBASO,KAAK7B,OATZ;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAAA,qBAaM6B,UAbN;AAAA;AAAA;AAAA;;AAcI,qBAAK5C,GAAL,CAAS6C,MAAT,CAAgBf,IAAhB,CAAqBc,UAArB;AAdJ;;AAAA;AAAA;AAAA,uBAmBQhD,SAAS,CAAC,UAAAY,EAAE;AAAA,yBAAI,MAAI,CAACR,GAAL,CAAS8C,YAAT,CAAsBV,GAAtB,CAA0B7B,IAA1B,EAAgCC,EAAhC,CAAJ;AAAA,iBAAH,CAAT,EAnBR;;AAAA;AAAA,sBAuBMmC,GAAG,CAACF,YAAJ,IAAoBE,GAAG,CAACH,aAvB9B;AAAA;AAAA;AAAA;;AAwBI,qBAAKvC,IAAL,CAAU0C,GAAV,GAAgBA,GAAhB;AAxBJ,kDAyBW;AACLF,kBAAAA,YAAY,EAAEE,GAAG,CAACF,YADb;AAELD,kBAAAA,aAAa,EAAEG,GAAG,CAACH;AAFd,iBAzBX;;AAAA;AAAA,sBAgCMG,GAAG,CAACI,WAAJ,IAAmBJ,GAAG,CAACI,WAAJ,CAAgBzB,MAAhB,GAAyB,CAhClD;AAAA;AAAA;AAAA;;AAAA;AAAA,uBAiCUI,OAAO,CAACsB,GAAR,CAAYL,GAAG,CAACI,WAAJ,CAAgBE,GAAhB;AAAA,sFAAoB,kBAAOC,MAAP;AAAA;AAAA;AAAA;AAAA;AAAA,iCAEhC,MAAI,CAACnD,GAAL,CAASoD,OAAT,CAAiBD,MAAM,CAACE,EAAxB,CAFgC;AAAA;AAAA;AAAA;;AAAA;;AAAA;AAKpCF,4BAAAA,MAAM,GAAG,MAAI,CAACnD,GAAL,CAASsD,QAAT,CAAkBC,GAAlB,CAAsBJ,MAAtB,CAAT;;AACA,4BAAA,MAAI,CAACnD,GAAL,CAASwD,eAAT,CAAyBL,MAAzB;;AANoC;AAAA,mCAO9B,MAAI,CAACjD,IAAL,CAAUuD,cAAV,CAAyBN,MAAM,CAACE,EAAhC,CAP8B;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAApB;;AAAA;AAAA;AAAA;AAAA,oBAAZ,CAjCV;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,O;;;;;;;;;;;;;AA8CFK,MAAM,CAACC,OAAP,GAAiB5D,WAAjB","sourcesContent":["'use strict'\n\nconst queue = require('async/queue')\nconst promisify = require('promisify-es6')\nconst promiseToCallback = require('promise-to-callback')\n\nclass WorkerQueue {\n  /**\n   * Creates a new WorkerQueue.\n   *\n   * @param {DHT} dht\n   * @param {Run} run\n   * @param {Object} path\n   * @param {function} log\n   */\n  constructor (dht, run, path, log) {\n    this.dht = dht\n    this.run = run\n    this.path = path\n    this.log = log\n\n    this.concurrency = this.dht.concurrency\n    this.queue = this.setupQueue()\n    // a container for resolve/reject functions that will be populated\n    // when execute() is called\n    this.execution = null\n  }\n\n  /**\n   * Create the underlying async queue.\n   *\n   * @returns {Object}\n   */\n  setupQueue () {\n    const q = queue((peer, cb) => {\n      promiseToCallback(this.processNext(peer))(cb)\n    }, this.concurrency)\n\n    // If there's an error, stop the worker\n    q.error = (err) => {\n      this.log.error('queue', err)\n      this.stop(err)\n    }\n\n    // When all peers in the queue have been processed, stop the worker\n    q.drain = () => {\n      this.log('queue:drain')\n      this.stop()\n    }\n\n    // When a space opens up in the queue, add some more peers\n    q.unsaturated = () => {\n      if (this.running) {\n        this.fill()\n      }\n    }\n\n    q.buffer = 0\n\n    return q\n  }\n\n  /**\n   * Stop the worker, optionally providing an error to pass to the worker's\n   * callback.\n   *\n   * @param {Error} err\n   */\n  stop (err) {\n    if (!this.running) {\n      return\n    }\n\n    this.running = false\n    this.queue.kill()\n    this.log('worker:stop, %d workers still running', this.run.workers.filter(w => w.running).length)\n    if (err) {\n      this.execution.reject(err)\n    } else {\n      this.execution.resolve()\n    }\n  }\n\n  /**\n   * Use the queue from async to keep `concurrency` amount items running\n   * per path.\n   *\n   * @return {Promise<void>}\n   */\n  async execute () {\n    this.running = true\n    // store the promise resolution functions to be resolved at end of queue\n    this.execution = {}\n    const execPromise = new Promise((resolve, reject) => Object.assign(this.execution, { resolve, reject }))\n    // start queue\n    this.fill()\n    // await completion\n    await execPromise\n  }\n\n  /**\n   * Add peers to the worker queue until there are enough to satisfy the\n   * worker queue concurrency.\n   * Note that we don't want to take any more than those required to satisfy\n   * concurrency from the peers-to-query queue, because we always want to\n   * query the closest peers to the key first, and new peers are continously\n   * being added to the peers-to-query queue.\n   */\n  fill () {\n    // Note:\n    // - queue.running(): number of items that are currently running\n    // - queue.length(): the number of items that are waiting to be run\n    while (this.queue.running() + this.queue.length() < this.concurrency &&\n           this.path.peersToQuery.length > 0) {\n      this.queue.push(this.path.peersToQuery.dequeue())\n    }\n  }\n\n  /**\n   * Process the next peer in the queue\n   *\n   * @param {PeerId} peer\n   * @returns {Promise<void>}\n   */\n  async processNext (peer) {\n    if (!this.running) {\n      return\n    }\n\n    // The paths must be disjoint, meaning that no two paths in the Query may\n    // traverse the same peer\n    if (this.run.peersSeen.has(peer)) {\n      return\n    }\n\n    // Check if we've queried enough peers already\n    let continueQuerying, continueQueryingError\n    try {\n      continueQuerying = await this.run.continueQuerying(this)\n    } catch (err) {\n      continueQueryingError = err\n    }\n\n    // Abort and ignore any error if we're no longer running\n    if (!this.running) {\n      return\n    }\n\n    if (continueQueryingError) {\n      throw continueQueryingError\n    }\n\n    // No peer we're querying is closer, stop the queue\n    // This will cause queries that may potentially result in\n    // closer nodes to be ended, but it reduces overall query time\n    if (!continueQuerying) {\n      this.stop()\n      return\n    }\n\n    // Check if another path has queried this peer in the mean time\n    if (this.run.peersSeen.has(peer)) {\n      return\n    }\n    this.run.peersSeen.add(peer)\n\n    // Execute the query on the next peer\n    this.log('queue:work')\n    let state, execError\n    try {\n      state = await this.execQuery(peer)\n    } catch (err) {\n      execError = err\n    }\n\n    // Abort and ignore any error if we're no longer running\n    if (!this.running) {\n      return\n    }\n\n    this.log('queue:work:done', execError, state)\n\n    if (execError) {\n      throw execError\n    }\n\n    // If query is complete, stop all workers.\n    // Note: run.stop() calls stop() on all the workers, which kills the\n    // queue and resolves execution\n    if (state && state.queryComplete) {\n      this.log('query:complete')\n      this.run.stop()\n      return\n    }\n\n    // If path is complete, just stop this worker.\n    // Note: this.stop() kills the queue and resolves execution\n    if (state && state.pathComplete) {\n      this.stop()\n    }\n  }\n\n  /**\n   * Execute a query on the next peer.\n   *\n   * @param {PeerId} peer\n   * @returns {Promise<void>}\n   * @private\n   */\n  async execQuery (peer) {\n    let res, queryError\n    try {\n      res = await this.path.queryFunc(peer)\n    } catch (err) {\n      queryError = err\n    }\n\n    // Abort and ignore any error if we're no longer running\n    if (!this.running) {\n      return\n    }\n\n    if (queryError) {\n      this.run.errors.push(queryError)\n      return\n    }\n\n    // Add the peer to the closest peers we have successfully queried\n    await promisify(cb => this.run.peersQueried.add(peer, cb))()\n\n    // If the query indicates that this path or the whole query is complete\n    // set the path result and bail out\n    if (res.pathComplete || res.queryComplete) {\n      this.path.res = res\n      return {\n        pathComplete: res.pathComplete,\n        queryComplete: res.queryComplete\n      }\n    }\n\n    // If there are closer peers to query, add them to the queue\n    if (res.closerPeers && res.closerPeers.length > 0) {\n      await Promise.all(res.closerPeers.map(async (closer) => {\n        // don't add ourselves\n        if (this.dht._isSelf(closer.id)) {\n          return\n        }\n        closer = this.dht.peerBook.put(closer)\n        this.dht._peerDiscovered(closer)\n        await this.path.addPeerToQuery(closer.id)\n      }))\n    }\n  }\n}\n\nmodule.exports = WorkerQueue\n"]},"metadata":{},"sourceType":"script"}